{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py as pm\n",
    "import numpy as np\n",
    "import psutil as pu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score  \n",
    "\n",
    "training_file_path = 'db/BPI_Challenge_2012.XE-training.csv'\n",
    "testing_file_path = 'db/BPI_Challenge_2012.XE-test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load CSV with pandas and pm4py\n",
    "\n",
    "pm4py gives two extra columns: @@index and @@case_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_event_log(path):\n",
    "    event_log = pd.read_csv(path, sep=',')\n",
    "    event_log = pm.format_dataframe(\n",
    "        event_log, \n",
    "        case_id='case concept:name', \n",
    "        activity_key='event concept:name', \n",
    "        timestamp_key='event time:timestamp'\n",
    "    )\n",
    "    return event_log\n",
    "#event_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genernal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that finds the length of the longest trace in a list of traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_trace(traces):\n",
    "    max = 0\n",
    "    for trace in traces:\n",
    "        if trace.shape[0] > max:\n",
    "            max = trace.shape[0]\n",
    "    return max\n",
    "\n",
    "def get_all_Activities():\n",
    "    df = format_event_log(training_file_path)\n",
    "    arr = df['event concept:name'].unique()\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that adds the Ground truth columns for event and time of the event\n",
    "- Every value in the ground truth columns is the actual next event or time of the next evet in the data set\n",
    "- Used for naive simulator\n",
    "- Used for verification purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume sorted by caseID and time\n",
    "def caseHasNextEvent(df, index):\n",
    "    if index >= len(df) - 1:\n",
    "        return False\n",
    "    if df.loc[index, 'case concept:name'] == df.loc[index+1, 'case concept:name']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def writeGroundtruth(df):\n",
    "    df = df.sort_values(by=['case concept:name','event time:timestamp'])\n",
    "    #add new columns containing the name of the next event in the case and the time when it happens\n",
    "    df = df.assign(ground_truth_activity='')\n",
    "    df = df.assign(ground_truth_time='')\n",
    "\n",
    "    for ind in df.index:\n",
    "        if caseHasNextEvent(df, ind):\n",
    "            df.at[ind,'ground_truth_activity'] = df.loc[ind+1,'event concept:name']\n",
    "            df.at[ind,'ground_truth_time'] = df.loc[ind+1, 'event time:timestamp']\n",
    "        else:\n",
    "            df.at[ind,'ground_truth_activity'] = None\n",
    "            df.at[ind,'ground_truth_time'] = None\n",
    "    return df\n",
    "\n",
    "#df_event = writeGroundtruth(event_log)\n",
    "#df_event.to_csv('check_writeGroundtruth_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTimeDifference(df):\n",
    "    # df['time_until_next_event'] = 0  # initialize new column with zeros\n",
    "    df = df.assign(time_until_next_event=0) # initialize new column\n",
    "\n",
    "    # iterate over each row of the dataframe\n",
    "    for i, row in df.iterrows():        \n",
    "        # check if there is a next row with the same case\n",
    "        if caseHasNextEvent(df, i):\n",
    "            nextTime = df.loc[i+1, 'event time:timestamp']\n",
    "            currentTime = row['event time:timestamp']\n",
    "            timeDiff = nextTime - currentTime\n",
    "            df.at[i, 'ground_truth_timeinseconds'] = timeDiff.total_seconds()\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that splits the data set into separate traces\n",
    "- Parameter $traces$ is a list containing all the individual traces\n",
    "- Each trace in traces is a list containing all the events in the trace in the order that they happen\n",
    "- Helper method for prefix extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_traces(event_log):\n",
    "    traces = []\n",
    "    last_location = 0\n",
    "    for j in range (0, event_log.shape[0] - 1):\n",
    "        if not event_log[\"case concept:name\"][j] == event_log[\"case concept:name\"][j + 1]:\n",
    "            traces.append(event_log.loc[last_location : j].reset_index())\n",
    "            last_location = j + 1\n",
    "    traces.append(event_log.loc[last_location : event_log.shape[0] - 1].reset_index())\n",
    "    return traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that deletes traces from an event log that do not end before a specified time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_traces(event_log, end_time):\n",
    "    traces = split_into_traces(event_log)\n",
    "    del_tr = []\n",
    "    for j in range(len(traces)):\n",
    "        for k in traces[j].index:\n",
    "            trace_ts = traces[j][\"event time:timestamp\"][k]\n",
    "        if trace_ts > end_time:\n",
    "            del_tr.append(traces[j][\"case concept:name\"][0])\n",
    "    \n",
    "    for j in range(len(del_tr)):\n",
    "        event_log = event_log[event_log[\"case concept:name\"] != del_tr[j]]\n",
    "    return event_log.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefix extraction\n",
    "- extract event lists of odd length like 1, 3, 5, 7, 9, 11, 13, 15 from the traces for prediction\n",
    "- and the ground truth\n",
    "- store them in a list of prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_extraction(traces, prefix_lengths):\n",
    "    prefixes = []\n",
    "    for trace in traces:\n",
    "        for length in prefix_lengths:\n",
    "            if trace.shape[0] >= length:\n",
    "                prefixes.append(trace.loc[:length - 1])\n",
    "    return prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation encoding\n",
    "\n",
    "- encode traces into numerical data for prediction\n",
    "- adds the ground truth at the end of the encoded prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(event_log):\n",
    "    events = []\n",
    "    events = event_log['event concept:name'].unique()\n",
    "\n",
    "    events_dict = {'ground_truth_activity' : 'truth', 'ground_truth_time' : 'truth'}\n",
    "    for event in events:\n",
    "        events_dict[event] = 0\n",
    "    return events_dict\n",
    "\n",
    "def aggregation_encoding(prefixes, event_log):\n",
    "    event_dict = create_dict(event_log)\n",
    "    aggregation_encoding = pd.DataFrame(event_dict, index=[0])\n",
    "    aggregation_encoding = aggregation_encoding.drop(0)\n",
    "    #new_encoding = ['truth', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    index = 0\n",
    "    for prefix in prefixes:\n",
    "        current_dict = create_dict(event_log)\n",
    "        current_dict['ground_truth_activity'] = prefix['ground_truth_activity'][len(prefix.index) - 1]\n",
    "        current_dict['ground_truth_time'] = prefix['ground_truth_time'][len(prefix.index) - 1]\n",
    "        for event in prefix[\"event concept:name\"]:\n",
    "            current_dict[event] = current_dict[event] + 1\n",
    "        aggregation_encoding.loc[index] = current_dict.values()\n",
    "        index += 1\n",
    "    return aggregation_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregation_encoding(path, type):\n",
    "    event_log = format_event_log(path)\n",
    "#     if type == \"train\":\n",
    "#         time_split = pd.to_datetime(\"02-01-2012 15:28:39.244\",format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "#         event_log = delete_traces(event_log, pd.Timestamp(, tz='GMT+0'))\n",
    "#         print(\"done remove\")\n",
    "    traces = split_into_traces(event_log)\n",
    "    prefix_lengths = []\n",
    "    if type == \"train\":\n",
    "        prefix_lengths = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
    "    if type == \"test\":\n",
    "        prefix_lengths = [x for x in range(1, find_longest_trace(traces) + 1)]\n",
    "    prefixes = prefix_extraction(traces, prefix_lengths)\n",
    "    aggregation = aggregation_encoding(prefixes, event_log)\n",
    "    if type == \"train\":\n",
    "        aggregation.to_csv(\"db/aggregation_encoding_train.csv\")\n",
    "    if type == \"test\":\n",
    "        aggregation.to_csv(\"db/aggregation_encoding_test.csv\")\n",
    "    return aggregation\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_aggregation():\n",
    "    train_file_path = 'db/Ground_Turth.csv'\n",
    "    test_file_path = 'db/Naive_Estimator.csv'\n",
    "    train_aggregation = get_aggregation_encoding(train_file_path, \"train\")\n",
    "    test_aggregation = get_aggregation_encoding(test_file_path, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_X_Y(df):\n",
    "    dependent_Variable = 'ground_truth'\n",
    "    independent_Variable = get_all_Activities().tolist()\n",
    "\n",
    "    dict_activity_to_int = {a: independent_Variable.index(a) for a in independent_Variable}\n",
    "    \n",
    "    X = df[independent_Variable]\n",
    "    Y = df[dependent_Variable].replace(dict_activity_to_int)\n",
    "\n",
    "    print(independent_Variable)\n",
    "    return X, Y, dict_activity_to_int\n",
    "\n",
    "def get_Regression_model_scaler(df_training_encoded):\n",
    "    X, Y, _ = process_X_Y(df_training_encoded)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, Y)\n",
    "    \n",
    "    intercept = model.intercept_\n",
    "\n",
    "    return model, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Estimator (S1)\n",
    "1. for each row find next activity of the case and its timestamp\n",
    "2. compute the time it take for the next event to be log in the db\n",
    "3. for each activity find the most common next activity (mode)\n",
    "4. for each activity find the average time between next activity\n",
    "5. Have 3. and 4. in a DataFrame\n",
    "6. base on the current activity write the prediction of the next activity and time it will take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_estimators():\n",
    "    df_train = format_event_log(training_file_path)\n",
    "    df_train = writeGroundtruth(df_train)\n",
    "    df_train = computeTimeDifference(df_train)\n",
    "\n",
    "    df_test = format_event_log(testing_file_path)\n",
    "    df_test = writeGroundtruth(df_test)\n",
    "    df_test = computeTimeDifference(df_test)\n",
    "\n",
    "    df_naive_predictor_dict = df_train.groupby(['event concept:name']).agg(\n",
    "        naive_prediction_activity = ('ground_truth_activity', pd.Series.mode),\n",
    "        naive_prediction_time = ('ground_truth_timeinseconds', 'mean')\n",
    "    )\n",
    "\n",
    "    df_test = df_test.assign(naive_prediction_activity='')\n",
    "    df_test = df_test.assign(naive_prediction_time=0)\n",
    "    for i, r in df_test.iterrows():\n",
    "        this_event = r['event concept:name']\n",
    "        next_event = df_naive_predictor_dict.loc[this_event,'naive_prediction_activity']\n",
    "        next_event_time = df_naive_predictor_dict.loc[this_event,'naive_prediction_time']\n",
    "        df_test.at[i,'naive_prediction_activity'] = next_event\n",
    "        df_test.at[i,'naive_prediction_time'] = next_event_time\n",
    "    df_train.to_csv('db/Ground_Truth.csv')\n",
    "    df_test.to_csv('db/Naive_Estimator.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivalue Regression (S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_estimator():\n",
    "    df_encoded_train = pd.read_csv('db/aggregation_encoding.csv')\n",
    "    df_encoded_test = pd.read_csv('db/aggregation_encoding_test.csv')\n",
    "    \n",
    "    df_output = format_event_log('db/Naive_Estimator.csv')\n",
    "    \n",
    "    model, scaler = get_Regression_model_scaler(df_encoded_train)\n",
    "    X_test, Y_test, dict_activities_int = process_X_Y(df_encoded_test)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    dict_int_activities = {v: k for k, v in dict_activities_int.items()}\n",
    "\n",
    "    predicts = model.predict(X_test)\n",
    "    predicts = [dict_int_activities[p] for p in predicts]\n",
    "\n",
    "    df_output['RE P activities'] = predicts\n",
    "    df_output.to_csv(\"db/Regression_Estimator.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Functionalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot representation of the entire data set in chronological order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_data():\n",
    "    df_BPI_train = pd.read_csv(training_file_path)\n",
    "    df_BPI_test = pd.read_csv(testing_file_path)\n",
    "    df_BPI = pd.concat([df_BPI_train, df_BPI_train])\n",
    "    \n",
    "    df_BPI['event time:timestamp'] = pd.to_datetime(df_BPI['event time:timestamp'],format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    \n",
    "    ax = sns.relplot(data=df_BPI, x='event time:timestamp', y='case concept:name', hue='event concept:name', height=10, aspect=1.5)\n",
    "    plt.ylim(max(df_BPI['case concept:name']), min(df_BPI['case concept:name']))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot representation of the data set split into training and test sets, after the removal of unusable traces from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_split_data():\n",
    "    df_BPI_train = pd.read_csv(training_file_path)\n",
    "    df_BPI_test = pd.read_csv(testing_file_path)\n",
    "    df_BPI = pd.concat([df_BPI_train, df_BPI_train])\n",
    "    \n",
    "    df_BPI['event time:timestamp'] = pd.to_datetime(df_BPI['event time:timestamp'],format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    df_BPI['case REG_DATE'] = pd.to_datetime(df_BPI['case REG_DATE'],format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    splittime = pd.to_datetime(\"02-01-2012 15:28:39.244\",format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    plt_splitline = df_BPI.copy()\n",
    "    plt_splitline['event time:timestamp'] = splittime\n",
    "    plt_splitline['event concept:name'] = \"test/training split\"\n",
    "    \n",
    "    df_BPI = df_BPI.sort_values(by=['case concept:name','event time:timestamp'], ignore_index=True)\n",
    "    df_BPI_train = delete_traces(df_BPI.copy(), splittime)\n",
    "    df_BPI_test = df_BPI[df_BPI['case REG_DATE'] >= splittime]\n",
    "    \n",
    "    df_BPI = pd.concat([df_BPI_train, df_BPI_test])\n",
    "    df_BPI = df_BPI.sort_values(by='event time:timestamp', ignore_index=True)\n",
    "    df_BPI = pd.concat([df_BPI, plt_splitline])\n",
    "    \n",
    "    ax = sns.relplot(data=df_BPI, x='event time:timestamp', y='case concept:name', hue='event concept:name', height=10, aspect=1.5)\n",
    "    plt.ylim(max(df_BPI['case concept:name']), min(df_BPI['case concept:name']))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot representation of the data set with time arrangement of events relative to the start of their respective case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_case_relative():\n",
    "    df_BPI_train = pd.read_csv(training_file_path)\n",
    "    df_BPI_test = pd.read_csv(testing_file_path)\n",
    "    df_BPI = pd.concat([df_BPI_train, df_BPI_train])\n",
    "    \n",
    "    df_BPI['event time:timestamp'] = pd.to_datetime(df_BPI['event time:timestamp'],format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    df_BPI['case REG_DATE'] = pd.to_datetime(df_BPI['case REG_DATE'],format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    \n",
    "    df_BPI['event time:case relative'] = pd.to_datetime(df_BPI['event time:timestamp'], format=\"%Y-%m-%d %H:%M:%S.%f\") - pd.to_datetime(df_BPI['case REG_DATE'], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    \n",
    "    ax = sns.relplot(data=df_BPI, x='event time:case relative', y='case concept:name', hue='event concept:name', markers=\"x\", height=7, aspect=1.5)\n",
    "    plt.ylim(max(df_BPI['case concept:name']), min(df_BPI['case concept:name']))\n",
    "    plt.xlim(0, )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_model(predictor_path, prediction_activity, prediction_time):\n",
    "    df_error_model = pd.read_csv(predictor_path)\n",
    "    df_error_model['error_activity'] = df_error_model['ground_truth_activity'] == df_error_model[prediction_activity]\n",
    "    df_error_model['error_time'] = df_error_model[prediction_time] - df_error_model['ground_truth_timeinseconds']\n",
    "    correct_predictions = df_error_model['error_activity'].value_counts()\n",
    "    percentage = correct_predictions[True] / len(df_error_model['error_activity']) * 100\n",
    "    mean_absolute_error = df_error_model['error_time'].mean()\n",
    "    print(f'Percentage of True values: {percentage:.1f}%')\n",
    "    print(mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory and CPU Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_memory_cpu() : \n",
    "    print('The CPU usage is: ', pu.cpu_percent(4))\n",
    "    print('RAM memory % used:', pu.virtual_memory()[2])\n",
    "    print('RAM Used (GB):', pu.virtual_memory()[3]/1000000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main class\n",
    "1. All functions that are needed all called in this cell.\n",
    "2. No other cell runs code other than the main cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_2428\\945299891.py:3: DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0. the format_dataframe function does not need application anymore.\n",
      "  event_log = pm.format_dataframe(\n",
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_2428\\945299891.py:3: DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0. the format_dataframe function does not need application anymore.\n",
      "  event_log = pm.format_dataframe(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of True values: 66.5%\n",
      "-112590.13210017119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_2428\\945299891.py:3: DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0. the format_dataframe function does not need application anymore.\n",
      "  event_log = pm.format_dataframe(\n",
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_2428\\945299891.py:3: DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0. the format_dataframe function does not need application anymore.\n",
      "  event_log = pm.format_dataframe(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A_SUBMITTED', 'A_PARTLYSUBMITTED', 'A_PREACCEPTED', 'W_Completeren aanvraag', 'A_ACCEPTED', 'A_FINALIZED', 'O_SELECTED', 'O_CREATED', 'O_SENT', 'W_Nabellen offertes', 'O_SENT_BACK', 'W_Valideren aanvraag', 'O_ACCEPTED', 'A_REGISTERED', 'A_APPROVED', 'A_ACTIVATED', 'O_CANCELLED', 'W_Wijzigen contractgegevens', 'A_DECLINED', 'A_CANCELLED', 'W_Afhandelen leads', 'O_DECLINED', 'W_Nabellen incomplete dossiers', 'W_Beoordelen fraude']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_2428\\945299891.py:3: DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0. the format_dataframe function does not need application anymore.\n",
      "  event_log = pm.format_dataframe(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['W_Wijzigen contractgegevens'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m naive_estimators()\n\u001b[0;32m      2\u001b[0m error_model(\u001b[39m'\u001b[39m\u001b[39mdb/Naive_Estimator.csv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnaive_prediction_activity\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnaive_prediction_time\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m regression_estimator()\n",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m, in \u001b[0;36mregression_estimator\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m df_output \u001b[39m=\u001b[39m format_event_log(\u001b[39m'\u001b[39m\u001b[39mdb/Naive_Estimator.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m model, scaler \u001b[39m=\u001b[39m get_Regression_model_scaler(df_encoded_train)\n\u001b[1;32m----> 8\u001b[0m X_test, Y_test, dict_activities_int \u001b[39m=\u001b[39m process_X_Y(df_encoded_test)\n\u001b[0;32m      9\u001b[0m X_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[0;32m     10\u001b[0m dict_int_activities \u001b[39m=\u001b[39m {v: k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m dict_activities_int\u001b[39m.\u001b[39mitems()}\n",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m, in \u001b[0;36mprocess_X_Y\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      3\u001b[0m independent_Variable \u001b[39m=\u001b[39m get_all_Activities()\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m      5\u001b[0m dict_activity_to_int \u001b[39m=\u001b[39m {a: independent_Variable\u001b[39m.\u001b[39mindex(a) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m independent_Variable}\n\u001b[1;32m----> 7\u001b[0m X \u001b[39m=\u001b[39m df[independent_Variable]\n\u001b[0;32m      8\u001b[0m Y \u001b[39m=\u001b[39m df[dependent_Variable]\u001b[39m.\u001b[39mreplace(dict_activity_to_int)\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(independent_Variable)\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gebruiker\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['W_Wijzigen contractgegevens'] not in index\""
     ]
    }
   ],
   "source": [
    "naive_estimators()\n",
    "error_model('db/Naive_Estimator.csv', 'naive_prediction_activity', 'naive_prediction_time')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b70c613820eb82f44088773ffc2add453462ad8308f78b60a549bce82e221db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
