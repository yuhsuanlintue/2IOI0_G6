{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py as pm\n",
    "import numpy as np\n",
    "import psutil as pu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score  \n",
    "\n",
    "training_file_path = 'db/BPI_Challenge_2012.XE-training.csv'\n",
    "testing_file_path = 'db/BPI_Challenge_2012.XE-test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load CSV with pandas and pm4py\n",
    "\n",
    "pm4py gives two extra columns: @@index and @@case_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_event_log(path):\n",
    "    event_log = pd.read_csv(path, sep=',')\n",
    "    event_log = pm.format_dataframe(\n",
    "        event_log, \n",
    "        case_id='case concept:name', \n",
    "        activity_key='event concept:name', \n",
    "        timestamp_key='event time:timestamp'\n",
    "    )\n",
    "    return event_log\n",
    "#event_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genernal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that finds the length of the longest trace in a list of traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_trace(traces):\n",
    "    max = 0\n",
    "    for trace in traces:\n",
    "        if trace.shape[0] > max:\n",
    "            max = trace.shape[0]\n",
    "    return max\n",
    "\n",
    "def get_all_Activities():\n",
    "    df = format_event_log(training_file_path)\n",
    "    arr = df['event concept:name'].unique()\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that adds the Ground truth columns for event and time of the event\n",
    "- Every value in the ground truth columns is the actual next event or time of the next evet in the data set\n",
    "- Used for naive simulator\n",
    "- Used for verification purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume sorted by caseID and time\n",
    "def caseHasNextEvent(df, index):\n",
    "    if index >= len(df) - 1:\n",
    "        return False\n",
    "    if df.loc[index, 'case concept:name'] == df.loc[index+1, 'case concept:name']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def writeGroundtruth(df):\n",
    "    df = df.sort_values(by=['case concept:name','event time:timestamp'])\n",
    "    #add new columns containing the name of the next event in the case and the time when it happens\n",
    "    df = df.assign(ground_truth_activity='')\n",
    "    df = df.assign(ground_truth_time='')\n",
    "\n",
    "    for ind in df.index:\n",
    "        if caseHasNextEvent(df, ind):\n",
    "            df.at[ind,'ground_truth_activity'] = df.loc[ind+1,'event concept:name']\n",
    "            df.at[ind,'ground_truth_time'] = df.loc[ind+1, 'event time:timestamp']\n",
    "        else:\n",
    "            df.at[ind,'ground_truth_activity'] = None\n",
    "            df.at[ind,'ground_truth_time'] = None\n",
    "    return df\n",
    "\n",
    "#df_event = writeGroundtruth(event_log)\n",
    "#df_event.to_csv('check_writeGroundtruth_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTimeDifference(df):\n",
    "    # df['time_until_next_event'] = 0  # initialize new column with zeros\n",
    "    df = df.assign(time_until_next_event=0) # initialize new column\n",
    "\n",
    "    # iterate over each row of the dataframe\n",
    "    for i, row in df.iterrows():        \n",
    "        # check if there is a next row with the same case\n",
    "        if caseHasNextEvent(df, i):\n",
    "            nextTime = df.loc[i+1, 'event time:timestamp']\n",
    "            currentTime = row['event time:timestamp']\n",
    "            timeDiff = nextTime - currentTime\n",
    "            df.at[i, 'ground_truth_timeinseconds'] = timeDiff.total_seconds()\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that splits the data set into separate traces\n",
    "- Parameter $traces$ is a list containing all the individual traces\n",
    "- Each trace in traces is a list containing all the events in the trace in the order that they happen\n",
    "- Helper method for prefix extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_traces(event_log):\n",
    "    traces = []\n",
    "    last_location = 0\n",
    "    for j in range (0, event_log.shape[0] - 1):\n",
    "        if not event_log[\"case concept:name\"][j] == event_log[\"case concept:name\"][j + 1]:\n",
    "            traces.append(event_log.loc[last_location : j].reset_index())\n",
    "            last_location = j + 1\n",
    "    traces.append(event_log.loc[last_location : event_log.shape[0] - 1].reset_index())\n",
    "    return traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that deletes traces from an event log that do not end before a specified time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_traces(event_log, end_time):\n",
    "    traces = split_into_traces(event_log)\n",
    "    del_tr = []\n",
    "    for j in range(len(traces)):\n",
    "        for k in traces[j].index:\n",
    "            trace_ts = traces[j][\"event time:timestamp\"][k]\n",
    "        if trace_ts > end_time:\n",
    "            del_tr.append(traces[j][\"case concept:name\"][0])\n",
    "    \n",
    "    for j in range(len(del_tr)):\n",
    "        event_log = event_log[event_log[\"case concept:name\"] != del_tr[j]].reset_index()\n",
    "    event_log.to_csv(\"db/removed_overlap.csv\")\n",
    "    return event_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefix extraction\n",
    "- extract event lists of odd length like 1, 3, 5, 7, 9, 11, 13, 15 from the traces for prediction\n",
    "- and the ground truth\n",
    "- store them in a list of prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_extraction(traces, prefix_lengths):\n",
    "    prefixes = []\n",
    "    for trace in traces:\n",
    "        for length in prefix_lengths:\n",
    "            if trace.shape[0] >= length:\n",
    "                prefixes.append(trace.loc[:length - 1])\n",
    "    return prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation encoding\n",
    "\n",
    "- encode traces into numerical data for prediction\n",
    "- adds the ground truth at the end of the encoded prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(event_log):\n",
    "    events = []\n",
    "    events = event_log['event concept:name'].unique()\n",
    "\n",
    "    events_dict = {'ground_truth_activity' : 'truth', 'ground_truth_time' : 'truth'}\n",
    "    for event in events:\n",
    "        events_dict[event] = 0\n",
    "    return events_dict\n",
    "\n",
    "def aggregation_encoding(prefixes, event_log):\n",
    "    event_dict = create_dict(event_log)\n",
    "    aggregation_encoding = pd.DataFrame(event_dict, index=[0])\n",
    "    aggregation_encoding = aggregation_encoding.drop(0)\n",
    "    #new_encoding = ['truth', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    index = 0\n",
    "    for prefix in prefixes:\n",
    "        current_dict = create_dict(event_log)\n",
    "        current_dict['ground_truth_activity'] = prefix['ground_truth_activity'][len(prefix.index) - 1]\n",
    "        current_dict['ground_truth_time'] = prefix['ground_truth_time'][len(prefix.index) - 1]\n",
    "        for event in prefix[\"event concept:name\"]:\n",
    "            current_dict[event] = current_dict[event] + 1\n",
    "        aggregation_encoding.loc[index] = current_dict.values()\n",
    "        index += 1\n",
    "    return aggregation_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregation_encoding(path, type):\n",
    "    event_log = format_event_log(path)\n",
    "    if type == \"train\":\n",
    "        time_split = pd.to_datetime(\"02-01-2012 15:28:39.244\",format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "        event_log = delete_traces(event_log, pd.Timestamp(time_split , tz='GMT+0'))\n",
    "        event_log = format_event_log(\"db/removed_overlap.csv\")\n",
    "        print(\"done remove\")\n",
    "    traces = split_into_traces(event_log)\n",
    "    prefix_lengths = []\n",
    "    if type == \"train\":\n",
    "        prefix_lengths = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
    "    if type == \"test\":\n",
    "        prefix_lengths = [x for x in range(1, find_longest_trace(traces) + 1)]\n",
    "    prefixes = prefix_extraction(traces, prefix_lengths)\n",
    "    aggregation = aggregation_encoding(prefixes, event_log)\n",
    "    if type == \"train\":\n",
    "        aggregation.to_csv(\"db/aggregation_encoding_train.csv\")\n",
    "    if type == \"test\":\n",
    "        aggregation.to_csv(\"db/aggregation_encoding_test.csv\")\n",
    "    return aggregation\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_aggregation():\n",
    "    train_file_path = 'db/Ground_Turth.csv'\n",
    "    test_file_path = 'db/Naive_Estimator.csv'\n",
    "    train_aggregation = get_aggregation_encoding(train_file_path, \"train\")\n",
    "    test_aggregation = get_aggregation_encoding(test_file_path, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_X_Y(df):\n",
    "    dependent_Variable = 'ground_truth'\n",
    "    independent_Variable = get_all_Activities().tolist()\n",
    "\n",
    "    dict_activity_to_int = {a: independent_Variable.index(a) for a in independent_Variable}\n",
    "    \n",
    "    X = df[independent_Variable]\n",
    "    Y = df[dependent_Variable].replace(dict_activity_to_int)\n",
    "\n",
    "    print(independent_Variable)\n",
    "    return X, Y, dict_activity_to_int\n",
    "\n",
    "def get_Regression_model_scaler(df_training_encoded):\n",
    "    X, Y, _ = process_X_Y(df_training_encoded)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, Y)\n",
    "    \n",
    "    intercept = model.intercept_\n",
    "\n",
    "    return model, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Estimator (S1)\n",
    "1. for each row find next activity of the case and its timestamp\n",
    "2. compute the time it take for the next event to be log in the db\n",
    "3. for each activity find the most common next activity (mode)\n",
    "4. for each activity find the average time between next activity\n",
    "5. Have 3. and 4. in a DataFrame\n",
    "6. base on the current activity write the prediction of the next activity and time it will take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_estimators():\n",
    "    df_train = format_event_log(training_file_path)\n",
    "    df_train = writeGroundtruth(df_train)\n",
    "    df_train = computeTimeDifference(df_train)\n",
    "\n",
    "    df_test = format_event_log(testing_file_path)\n",
    "    df_test = writeGroundtruth(df_test)\n",
    "    df_test = computeTimeDifference(df_test)\n",
    "\n",
    "    df_naive_predictor_dict = df_train.groupby(['event concept:name']).agg(\n",
    "        naive_prediction_activity = ('ground_truth_activity', pd.Series.mode),\n",
    "        naive_prediction_time = ('ground_truth_timeinseconds', 'mean')\n",
    "    )\n",
    "\n",
    "    df_test = df_test.assign(naive_prediction_activity='')\n",
    "    df_test = df_test.assign(naive_prediction_time=0)\n",
    "    for i, r in df_test.iterrows():\n",
    "        this_event = r['event concept:name']\n",
    "        next_event = df_naive_predictor_dict.loc[this_event,'naive_prediction_activity']\n",
    "        next_event_time = df_naive_predictor_dict.loc[this_event,'naive_prediction_time']\n",
    "        df_test.at[i,'naive_prediction_activity'] = next_event\n",
    "        df_test.at[i,'naive_prediction_time'] = next_event_time\n",
    "    df_train.to_csv('db/Ground_Truth.csv')\n",
    "    df_test.to_csv('db/Naive_Estimator.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivalue Regression (S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_estimator():\n",
    "    df_encoded_train = pd.read_csv('db/aggregation_encoding_train.csv')\n",
    "    df_encoded_test = pd.read_csv('db/aggregation_encoding_test.csv')\n",
    "    \n",
    "    df_output = format_event_log('db/Naive_Estimator.csv')\n",
    "    df_output = computeTimeDifference(df_output)\n",
    "    \n",
    "    model, scaler = get_Regression_model_scaler(df_encoded_train)\n",
    "    X_test, Y_test, dict_activities_int = process_X_Y(df_encoded_test)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    dict_int_activities = {v: k for k, v in dict_activities_int.items()}\n",
    "\n",
    "    predicts = model.predict(X_test)\n",
    "    predicts = [dict_int_activities[p] for p in predicts]\n",
    "\n",
    "    df_output['RE P activities'] = predicts\n",
    "    df_output.to_csv(\"db/Regression_Estimator.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Functionalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot representation of the entire data set in chronological order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_data():\n",
    "    df_BPI_train = pd.read_csv(training_file_path)\n",
    "    df_BPI_test = pd.read_csv(testing_file_path)\n",
    "    df_BPI = pd.concat([df_BPI_train, df_BPI_train])\n",
    "    \n",
    "    df_BPI['event time:timestamp'] = pd.to_datetime(df_BPI['event time:timestamp'],format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    \n",
    "    ax = sns.relplot(data=df_BPI, x='event time:timestamp', y='case concept:name', hue='event concept:name', height=10, aspect=1.5)\n",
    "    plt.ylim(max(df_BPI['case concept:name']), min(df_BPI['case concept:name']))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot representation of the data set split into training and test sets, after the removal of unusable traces from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_split_data():\n",
    "    df_BPI_train = pd.read_csv(training_file_path)\n",
    "    df_BPI_test = pd.read_csv(testing_file_path)\n",
    "    df_BPI = pd.concat([df_BPI_train, df_BPI_train])\n",
    "    \n",
    "    df_BPI['event time:timestamp'] = pd.to_datetime(df_BPI['event time:timestamp'],format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    df_BPI['case REG_DATE'] = pd.to_datetime(df_BPI['case REG_DATE'],format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    splittime = pd.to_datetime(\"02-01-2012 15:28:39.244\",format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    plt_splitline = df_BPI.copy()\n",
    "    plt_splitline['event time:timestamp'] = splittime\n",
    "    plt_splitline['event concept:name'] = \"test/training split\"\n",
    "    \n",
    "    df_BPI = df_BPI.sort_values(by=['case concept:name','event time:timestamp'], ignore_index=True)\n",
    "    df_BPI_train = delete_traces(df_BPI.copy(), splittime)\n",
    "    df_BPI_test = df_BPI[df_BPI['case REG_DATE'] >= splittime]\n",
    "    \n",
    "    df_BPI = pd.concat([df_BPI_train, df_BPI_test])\n",
    "    df_BPI = df_BPI.sort_values(by='event time:timestamp', ignore_index=True)\n",
    "    df_BPI = pd.concat([df_BPI, plt_splitline])\n",
    "    \n",
    "    ax = sns.relplot(data=df_BPI, x='event time:timestamp', y='case concept:name', hue='event concept:name', height=10, aspect=1.5)\n",
    "    plt.ylim(max(df_BPI['case concept:name']), min(df_BPI['case concept:name']))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot representation of the data set with time arrangement of events relative to the start of their respective case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_case_relative():\n",
    "    df_BPI_train = pd.read_csv(training_file_path)\n",
    "    df_BPI_test = pd.read_csv(testing_file_path)\n",
    "    df_BPI = pd.concat([df_BPI_train, df_BPI_train])\n",
    "    \n",
    "    df_BPI['event time:timestamp'] = pd.to_datetime(df_BPI['event time:timestamp'],format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    df_BPI['case REG_DATE'] = pd.to_datetime(df_BPI['case REG_DATE'],format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    \n",
    "    df_BPI['event time:case relative'] = pd.to_datetime(df_BPI['event time:timestamp'], format=\"%Y-%m-%d %H:%M:%S.%f\") - pd.to_datetime(df_BPI['case REG_DATE'], format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    \n",
    "    ax = sns.relplot(data=df_BPI, x='event time:case relative', y='case concept:name', hue='event concept:name', markers=\"x\", height=7, aspect=1.5)\n",
    "    plt.ylim(max(df_BPI['case concept:name']), min(df_BPI['case concept:name']))\n",
    "    plt.xlim(0, )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_model(predictor_path, prediction_activity, prediction_time):\n",
    "    df_error_model = pd.read_csv(predictor_path)\n",
    "    df_error_model['error_activity'] = df_error_model['ground_truth_activity'] == df_error_model[prediction_activity]\n",
    "    df_error_model['error_time'] = df_error_model[prediction_time] - df_error_model['ground_truth_time']\n",
    "    correct_predictions = df_error_model['error_activity'].value_counts()\n",
    "    percentage = correct_predictions[True] / len(df_error_model['error_activity']) * 100\n",
    "    mean_absolute_error = df_error_model['error_time'].mean()\n",
    "    print(f'Percentage of True values: {percentage:.1f}%')\n",
    "    print(mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory and CPU Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_memory_cpu() : \n",
    "    print('The CPU usage is: ', pu.cpu_percent(4))\n",
    "    print('RAM memory % used:', pu.virtual_memory()[2])\n",
    "    print('RAM Used (GB):', pu.virtual_memory()[3]/1000000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main class\n",
    "1. All functions that are needed all called in this cell.\n",
    "2. No other cell runs code other than the main cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monik\\AppData\\Local\\Temp\\ipykernel_3248\\945299891.py:3: DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0. the format_dataframe function does not need application anymore.\n",
      "  event_log = pm.format_dataframe(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of True values: 66.5%\n",
      "-112590.13210017119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monik\\AppData\\Local\\Temp\\ipykernel_3248\\945299891.py:3: DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0. the format_dataframe function does not need application anymore.\n",
      "  event_log = pm.format_dataframe(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of True values: 65.6%\n",
      "-132092.67527787204\n"
     ]
    }
   ],
   "source": [
    "error_model('db/Naive_Estimator.csv', 'naive_prediction_activity', 'naive_prediction_time')\n",
    "error_model('db/Regression_Estimator.csv', 'RE P activities', 'naive_prediction_time')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b70c613820eb82f44088773ffc2add453462ad8308f78b60a549bce82e221db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
